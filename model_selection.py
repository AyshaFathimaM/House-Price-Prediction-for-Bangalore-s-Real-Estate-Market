# -*- coding: utf-8 -*-
"""model_selection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LYjl3lk2doF7H_CdEWAJRKseIsN5xsN3
"""
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from xgboost import XGBRegressor
import pandas as pd

def get_model_pipeline(categorical_features, numeric_features):
    """Create a pipeline with preprocessing and XGBoost."""
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
        ]
    )
    model = XGBRegressor(objective="reg:squarederror", random_state=42)
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('model', model)
    ])
    return pipeline

def tune_model(X_train, y_train, categorical_features, numeric_features):
    """Tune the model using RandomizedSearchCV with preprocessing."""
    pipeline = get_model_pipeline(categorical_features, numeric_features)

    param_dist = {
        'model__n_estimators': [100, 200, 300, 500],
        'model__learning_rate': [0.01, 0.05, 0.1, 0.2],
        'model__max_depth': [3, 5, 8, 10],
        'model__subsample': [0.7, 0.8, 0.9, 1.0],
        'model__colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'model__min_child_weight': [1, 3, 5],
        'model__gamma': [0, 0.1, 0.2]
    }

    print("Starting hyperparameter tuning...")
    random_search = RandomizedSearchCV(
        estimator=pipeline,
        param_distributions=param_dist,
        n_iter=10,
        scoring='neg_mean_squared_error',
        cv=3,
        verbose=2,
        random_state=42,
        n_jobs=-1
    )
    random_search.fit(X_train, y_train)
    print("RandomizedSearchCV completed successfully.")
    print("Best Parameters:", random_search.best_params_)
    print("Best Score:", random_search.best_score_)
    return random_search.best_estimator_

if __name__ == "__main__":
    # Load dataset
    df = pd.read_csv(r"C:\Users\Indra\Desktop\Praxis\Term 2\MLOPS\Bangalore Housing\Bengaluru_House_Data.csv")  # Replace with your dataset
    target = "price"  # Replace with target column name
    categorical_features = ["area_type", "location", "size", "society"]  # Replace with categorical features
    numeric_features = ["total_sqft", "bath", "balcony"]  # Replace with numeric features

    X = df[categorical_features + numeric_features]
    y = df[target]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    best_model = tune_model(X_train, y_train, categorical_features, numeric_features)

    if best_model is not None:
        print("Best Model Pipeline:", best_model)




